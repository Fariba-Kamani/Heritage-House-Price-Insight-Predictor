{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **EDA, Correlation and PPS Study**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Answer business requirement 1: \n",
        "    * The client is interested in discovering how the house attributes correlate with the sale price. Therefore, the client expects data visualisations of the correlated variables against the sale price to show that.\n",
        "* Investigate our hypothesis:\n",
        "    * H1, Houses with greater total living area (GrLivArea) are more expensive.\n",
        "    * H2, Higher overall quality (OverallQual) is associated with higher sale prices.\n",
        "    * H3, Houses with a garage (GarageArea > 0) sell for higher prices than those without.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/house_prices_records.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate code that answers business requirement 1 and can be used to build the Streamlit App\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = (pd.read_csv(\"outputs/datasets/collection/house_prices_records.csv\")\n",
        "    )\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are interested to get more familiar with the dataset, check variable type and distribution, missing levels and what these variables mean in a business context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "pandas_report = ProfileReport(df=df, minimal=True)\n",
        "pandas_report.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert float columns with whole numbers to int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "float_cols = df.select_dtypes(include='float').columns\n",
        "\n",
        "# Check which float columns contain only whole number values\n",
        "for col in float_cols:\n",
        "    if (df[col].dropna() % 1 == 0).all():\n",
        "        print(f\"{col} can be converted to int\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols_to_convert = [\n",
        "    '2ndFlrSF',\n",
        "    'BedroomAbvGr',\n",
        "    'EnclosedPorch',\n",
        "    'GarageYrBlt',\n",
        "    'LotFrontage',\n",
        "    'MasVnrArea',\n",
        "    'WoodDeckSF'\n",
        "]\n",
        "\n",
        "for col in cols_to_convert:\n",
        "    df[col] = df[col].astype('Int64')  # Supports missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[[\n",
        "    '2ndFlrSF', 'BedroomAbvGr', 'EnclosedPorch',\n",
        "    'GarageYrBlt', 'LotFrontage', 'MasVnrArea', 'WoodDeckSF'\n",
        "]].dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Handling of missing data and light Imputation for EDA Purposes Only to be able to use one-hot encoding of categorical columns, before correlation analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make a copy for EDA analysis\n",
        "df_eda_corr = df.copy()\n",
        "\n",
        "# Fill numeric columns with median\n",
        "num_cols = df_eda_corr.select_dtypes(include=['int64', 'float64']).columns\n",
        "df_eda_corr[num_cols] = df_eda_corr[num_cols].fillna(df_eda_corr[num_cols].median())\n",
        "\n",
        "# Fill categorical columns with mode\n",
        "cat_cols = df_eda_corr.select_dtypes(include='object').columns\n",
        "df_eda_corr[cat_cols] = df_eda_corr[cat_cols].fillna(df_eda_corr[cat_cols].mode().iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Correlation Study"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.encoding import OneHotEncoder\n",
        "encoder = OneHotEncoder(variables=df_eda_corr.columns[df.dtypes=='object'].to_list(), drop_last=False)\n",
        "df_ohe = encoder.fit_transform(df_eda_corr)\n",
        "print(df_ohe.shape)\n",
        "df_ohe.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use `.corr()` for `spearman` and `pearson` methods, and investigate the top 10 correlations\n",
        "* We know this command returns a pandas series and the first item is the correlation between SalePrice and SalePrice, which happens to be 1, so we exclude that with `[1:]`\n",
        "* We sort values considering the absolute value, by setting `key=abs`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_spearman = df_ohe.corr(method='spearman')['SalePrice'].sort_values(key=abs, ascending=False)[1:].head(10)\n",
        "corr_spearman"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We do the same for `pearson`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_pearson = df_ohe.corr(method='pearson')['SalePrice'].sort_values(key=abs, ascending=False)[1:].head(10)\n",
        "corr_pearson"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For both methods, we notice moderate to strong levels of correlation between SalePrice and a given variable. \n",
        "* Ideally, we pursue strong correlation levels.\n",
        "\n",
        "We will consider the top five correlation levels at `df_ohe` and will study the associated variables at `df`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_n = 5\n",
        "print(\"Pearson:\", corr_pearson[:top_n].index.to_list())\n",
        "print(\"Spearman:\", corr_spearman[:top_n].index.to_list())\n",
        "set(corr_pearson[:top_n].index.to_list() + corr_spearman[:top_n].index.to_list())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Therefore, we will study the following variables in the dataset. We aim to investigate whether a house with:\n",
        "\n",
        "* better overall material and finish,\n",
        "\n",
        "* a larger above-ground living area (ft²),\n",
        "\n",
        "* a larger garage area (ft²),\n",
        "\n",
        "* a larger basement area (ft²),\n",
        "\n",
        "* a larger first floor area (ft²), and\n",
        "\n",
        "* a more recent construction or remodel year\n",
        "\n",
        "tends to have a higher sale price.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars_to_study = ['1stFlrSF',\n",
        " 'GarageArea',\n",
        " 'GrLivArea',\n",
        " 'OverallQual',\n",
        " 'TotalBsmtSF',\n",
        " 'YearBuilt']\n",
        "vars_to_study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDA on selected variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_eda = df.filter(vars_to_study + ['SalePrice'])\n",
        "df_eda.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Variables Distribution by SalePrice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We plot the distribution (numerical and categorical) coloured by SalePrice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "# Columns that should use barplots (ordinal/categorical numerical)\n",
        "force_barplot = ['OverallQual']\n",
        "target_var = 'SalePrice'\n",
        "\n",
        "def plot_categorical(df, col, target_var):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    sns.countplot(data=df, x=col, hue=target_var, order=df[col].value_counts().index)\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.title(f\"{col}\", fontsize=20, y=1.05)\n",
        "    plt.show()\n",
        "\n",
        "def plot_numerical(df, col, target_var):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
        "\n",
        "    # Left: Distribution of the feature\n",
        "    if col in force_barplot:\n",
        "        # Use countplot if it's ordinal like OverallQual\n",
        "        sns.countplot(data=df, x=col, order=sorted(df[col].unique()), ax=axes[0])\n",
        "        axes[0].set_title(f\"Distribution of {col}\")\n",
        "    else:\n",
        "        # Use histogram for continuous variables\n",
        "        sns.histplot(data=df, x=col, kde=True, element=\"step\", ax=axes[0])\n",
        "        axes[0].set_title(f\"Distribution of {col}\")\n",
        "\n",
        "    # Right: Relationship with SalePrice\n",
        "    if col in force_barplot:\n",
        "        sns.barplot(data=df, x=col, y=target_var, order=sorted(df[col].unique()), ax=axes[1])\n",
        "        axes[1].set_ylabel(\"Average Sale Price\")\n",
        "        axes[1].set_title(f\"{col} vs {target_var} (Mean)\")\n",
        "    else:\n",
        "        sns.scatterplot(data=df, x=col, y=target_var, ax=axes[1])\n",
        "        axes[1].set_title(f\"{col} vs {target_var}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Loop through features\n",
        "for col in vars_to_study:\n",
        "    if df_eda[col].dtype == 'object':\n",
        "        plot_categorical(df_eda, col, target_var)\n",
        "        print(\"\\n\\n\")\n",
        "    else:\n",
        "        plot_numerical(df_eda, col, target_var)\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Insight from the plots:\n",
        "\n",
        "* 1stFlrSF: \n",
        "    * Distribution (Left Plot): The distribution is right-skewed, with most values between 800–1800 sq ft. There are fewer but notable outliers beyond 2000 sq ft.\n",
        "    * Correlation with SalePrice (Right Plot): There is a clear positive correlation — larger first-floor areas tend to correlate with higher sale prices.\n",
        "However, there's a lot of spread in SalePrice for a given 1stFlrSF (i.e., some 1500 sq ft homes sell low, some high), so other factors likely influence price as well.\n",
        "\n",
        "* GarageArea:\n",
        "    * Distribution (Left Plot): The distribution is slightly right-skewed. Most houses have garages between 200 and 700 sq ft, with a peak around 500–600 sq ft. A few outliers exceed 1000 sq ft.\n",
        "    * Correlation with SalePrice (Right Plot): A positive correlation exists, especially noticeable in the 400–800 sq ft range.\n",
        "However, there is significant spread — houses with the same garage size can vary widely in price.\n",
        "Some houses with tiny garages (0–200 sq ft) also have high prices — possibly indicating no garage but other strong contributing features.\n",
        "\n",
        "* GrLivArea:\n",
        "    * Distribution (Left Plot): Right-skewed distribution. Majority of houses fall between 1000 and 2000 sq ft. Very few homes exceed 3000 sq ft, and there are clear outliers above 4000–5000 sq ft.\n",
        "    * Correlation with SalePrice (Right Plot): Strong positive linear trend up to around 4000 sq ft, beyond which outliers appear. Houses larger than 2000 sq ft tend to fetch significantly higher prices.\n",
        "Data suggests larger living space directly correlates with increased sale price — one of the strongest relationships seen so far.\n",
        "\n",
        "* OverallQual:\n",
        "    * Distribution (Left Plot): Most houses are rated 5 to 7, with 5 and 6 being the most common. Very few properties have a rating of 1–3 or 9–10 — these are likely extreme cases (very poor or luxury homes).\n",
        "    * Correlation with SalePrice (Right Plot): Clear exponential increase in average sale price with higher quality. The mean sale price nearly doubles with each increment above quality level 6.\n",
        "This is a very strong predictor of price — arguably more direct than square footage.\n",
        "\n",
        "* TotalBsmtSF:\n",
        "    * Distribution (Left Plot): The variable is right-skewed with most values between 600–1500 sq ft. There's a noticeable peak around 1000 sq ft. A few outliers extend beyond 3000 sq ft, up to ~6000 — these may need closer inspection.\n",
        "    * Correlation with SalePrice (Right Plot): A positive linear trend with SalePrice up to ~3000 sq ft. Beyond 3000, the relationship weakens or shows more variance, possibly due to Fewer data points.\n",
        "Large basements not always translating to higher value.\n",
        "\n",
        "* YearBuilt:\n",
        "    * Distribution (Left Plot): Houses are not uniformly distributed across years. There's a strong peak after 2000, and visible construction booms around the 1950s–1970s and 2000s. A few houses date back to before 1900, which could be considered historical or outliers.\n",
        "    * Correlation with SalePrice (Right Plot): There is a positive correlation — newer houses tend to sell at higher prices. Houses built after 2000 show a more consistent concentration of high sale prices.Older homes have more price variability and are generally lower priced.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parallel Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from feature_engine.discretisation import ArbitraryDiscretiser\n",
        "import plotly.express as px\n",
        "\n",
        "# Make a copy of the dataframe\n",
        "df = df_eda.copy()\n",
        "\n",
        "# Define binning rules\n",
        "binning_dict = {\n",
        "    'OverallQual': [-np.Inf, 4, 6, 8, np.Inf],\n",
        "    'GrLivArea': [-np.Inf, 1200, 1800, 2500, np.Inf],\n",
        "    'GarageArea': [-np.Inf, 300, 600, 900, np.Inf],\n",
        "    '1stFlrSF': [-np.Inf, 1000, 1400, 1800, np.Inf],\n",
        "    'TotalBsmtSF': [-np.Inf, 800, 1200, 1600, np.Inf],\n",
        "    'YearBuilt': [-np.Inf, 1945, 1970, 2000, np.Inf],\n",
        "    'SalePrice': [-np.Inf, 150000, 200000, 300000, np.Inf]\n",
        "}\n",
        "\n",
        "# Discretize features\n",
        "disc = ArbitraryDiscretiser(binning_dict=binning_dict)\n",
        "df_binned = disc.fit_transform(df)\n",
        "\n",
        "# Replace bin numbers with readable labels\n",
        "label_maps = {}\n",
        "for col, bins in disc.binner_dict_.items():\n",
        "    labels_map = {}\n",
        "    n_classes = len(bins) - 1\n",
        "    for i in range(n_classes):\n",
        "        if i == 0:\n",
        "            labels_map[i] = f\"<{int(bins[1])}\"\n",
        "        elif i == n_classes - 1:\n",
        "            labels_map[i] = f\">{int(bins[-2])}\"\n",
        "        else:\n",
        "            labels_map[i] = f\"{int(bins[i])} to {int(bins[i+1])}\"\n",
        "    label_maps[col] = labels_map\n",
        "    df_binned[col] = df_binned[col].replace(labels_map)\n",
        "\n",
        "# Use the original SalePrice as numeric color and drop its binned version from axis\n",
        "fig = px.parallel_categories(\n",
        "    df_binned[\n",
        "        ['SalePrice', 'YearBuilt', 'GrLivArea', 'GarageArea', '1stFlrSF', 'TotalBsmtSF', 'OverallQual']\n",
        "    ],\n",
        "    color=df['SalePrice'],\n",
        "    color_continuous_scale=px.colors.sequential.Plasma,  # better contrast\n",
        "    labels={col: col for col in df_binned.columns},\n",
        "    title=\"Parallel Categories Plot\",\n",
        "    \n",
        ")\n",
        "\n",
        "fig.show(renderer=\"notebook\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Exploratory data analysis supports the hypothesis that a combination of quality, size, and recency significantly influences house prices in Ames, Iowa. In particular, overall quality, above-ground living area, and construction year appear to be the most consistently strong predictors of high sale prices across all visualizations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Note\n",
        "\n",
        "The EDA and correlation study notebook (`02-EDA_Correlation_PPS_Study.ipynb`) is not pushed to the repository to maintain a clean and lightweight codebase. This notebook contains exploratory and intermediate analysis steps that are not essential for reproduction of the final results. All key findings and visualizations are summarized in the report, and relevant processing steps are included in the main scripts."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
